{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9483da6",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7306f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from credentials import *\n",
    "import pandas as pd\n",
    "import tweepy, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d51fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_setup():\n",
    "    \"\"\"\n",
    "    Setup the Twitter's API\n",
    "    \"\"\"\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "    return tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "\n",
    "def return_tweets(query, since_d, until_d, lang):\n",
    "    tweet_list = []\n",
    "    retr_tweets = tweepy.Cursor(api.search, q=query, since=since_d, until=until_d, lang=lang, tweet_mode='extended').items()\n",
    "    for tweet in retr_tweets:\n",
    "        tweet_list.append(tweet._json)\n",
    "    return tweet_list\n",
    "\n",
    "\n",
    "def generate_json(tweet_list):\n",
    "    return json.dumps(tweet_list)\n",
    "\n",
    "\n",
    "def generate_json_file(tweet_list, file_path, file_name):\n",
    "    json_str = json.dumps(tweet_list)\n",
    "    json_file = open(file_path + file_name + '.json', 'w')\n",
    "    json_file.write(json_str)\n",
    "    json_file.close()\n",
    "    \n",
    "    \n",
    "def return_hashtag_list(tweet_list):\n",
    "    hashtag_list = []\n",
    "    for tweet in tweet_list:\n",
    "        if tweet['entities']['hashtags']:\n",
    "            for hashtag in tweet['entities']['hashtags']:\n",
    "                hashtag_list.append(hashtag['text'].lower())\n",
    "    return hashtag_list\n",
    "\n",
    "\n",
    "def return_hashtag_count(hashtag_list):\n",
    "    return pd.Series(hashtag_list).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e92a0",
   "metadata": {},
   "source": [
    "### __Automatic retrieving tweets from 2021-06-27 to 2021-07-03__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d33786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = api_setup()\n",
    "PATH = 'retrieved_tweets/'\n",
    "\n",
    "week = {\n",
    "    'day_1': ['2021-06-27','2021-06-28'],\n",
    "    'day_2': ['2021-06-28','2021-06-29'],\n",
    "    'day_3': ['2021-06-29','2021-06-30'],\n",
    "    'day_4': ['2021-06-30','2021-07-01'],\n",
    "    'day_5': ['2021-07-01','2021-07-02'],\n",
    "    'day_6': ['2021-07-02','2021-07-03'],\n",
    "    'day_7': ['2021-07-03','2021-07-04']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3d6b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching tweets from day  2021-06-27\n",
      "Fetching tweets from day  2021-06-28\n",
      "Fetching tweets from day  2021-06-29\n",
      "Fetching tweets from day  2021-06-30\n",
      "Fetching tweets from day  2021-07-01\n",
      "Fetching tweets from day  2021-07-02\n",
      "Fetching tweets from day  2021-07-03\n"
     ]
    }
   ],
   "source": [
    "for day in week.items():\n",
    "    since_date = day[1][0]\n",
    "    until_date = day[1][1]\n",
    "    file_name_1 = since_date+'_query.json'\n",
    "    file_name_2 = since_date+'_hasht.json'\n",
    "    print('Fetching tweets from day ', since_date)\n",
    "    tweet_list = return_tweets('cpi AND covid', since_date, until_date, 'pt')\n",
    "    print('Number of retrieved by cpi and covid query tweets: ', len(tweet_list))\n",
    "    generate_json_file(tweet_list, PATH, file_name_1)\n",
    "    print('JSON file created: '+PATH+file_name_1)\n",
    "    unique_hashtags = return_hashtag_count(return_hashtag_list(tweet_list))\n",
    "    print('Number of unique hashtags: ', unique_hashtags.shape[0])\n",
    "    hashtag_top10 = unique_hashtags.head(10).index\n",
    "    for i in range(0, len(hashtag_top10)):\n",
    "        hashtag_top10[i] = '#'+hashtag_top10[i]\n",
    "    print('The Top10 hashtags are: ', hashtag_top10)\n",
    "    hashtag_query = ' OR '.join(hashtag_top10)\n",
    "    tweet_list = return_tweets(hashtag_query, since_date, until_date, 'pt')\n",
    "    print('Number of retrieved by top 10 hashtags query tweets: ', len(tweet_list))\n",
    "    generate_json_file(tweet_list, PATH, file_name_2)\n",
    "    print('JSON file created: '+PATH+file_name_2)\n",
    "print('Finished day ', since_date)   \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "553567ffba0e17075731a4ce48ed70b0df537834ba59f7c38518d039f581877f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
