{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3c8aee-b4fd-446a-8ebf-bfb05062f86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output, display\n",
    "import os, datetime\n",
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee5937-0432-475d-9295-2c113ec064d4",
   "metadata": {},
   "source": [
    "## Fetching tweets with selected hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c705f4af-022b-483d-8048-2032f9746d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of extracted weeks:  26\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data/tweets/'\n",
    "\n",
    "week_list = [week_dir for week_dir in os.listdir(DATA_PATH) if os.path.isdir(DATA_PATH+week_dir) and not week_dir.endswith('.ipynb_checkpoints')]\n",
    "print('Amount of extracted weeks: ', len(week_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85b261a7-7439-4047-ae70-c35f983b65c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['week_01', 'week_02', 'week_03', 'week_04', 'week_05', 'week_06', 'week_07', 'week_08', 'week_09', 'week_10', 'week_11', 'week_12', 'week_pr_01', 'week_pr_02', 'week_13', 'week_14', 'week_15', 'week_16', 'week_17', 'week_pr_03', 'week_18', 'week_19', 'week_20', 'week_21', 'week_pr_04', 'week_22']\n"
     ]
    }
   ],
   "source": [
    "week_list.sort()\n",
    "week_list.remove('week_pr_01')\n",
    "week_list.insert(week_list.index('week_12')+1, 'week_pr_01')\n",
    "week_list.remove('week_pr_02')\n",
    "week_list.insert(week_list.index('week_pr_01')+1, 'week_pr_02')\n",
    "week_list.remove('week_pr_03')\n",
    "week_list.insert(week_list.index('week_17')+1, 'week_pr_03')\n",
    "week_list.remove('week_pr_04')\n",
    "week_list.insert(week_list.index('week_21')+1, 'week_pr_04')\n",
    "\n",
    "print(week_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e47ff6a-dfff-4554-85d4-c65c74d0d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hashtag groups\n",
    "neutral_hashtags = ['cpidacovid', 'cpidapandemia'] #, 'covid19', 'cpidacovid19','brasil']\n",
    "agt_cpi_hashtags = ['renanvagabundo', 'cpidocirco'] #, 'renansabiadetudo', 'euautorizopresidente', 'cpidotse', 'bolsonaropresidenteate2026']\n",
    "pro_cpi_hashtags = ['forabolsonaro', 'forabolsonarogenocida'] #, 'bolsonarogenocida', 'cpidogenocidio', '29mforabolsonaro', '3jforabolsonaro']\n",
    "selected_hashtags = neutral_hashtags+agt_cpi_hashtags+pro_cpi_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec58eb1-8c51-49be-b6e0-e9a24f7bd703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpidacovid',\n",
       " 'cpidapandemia',\n",
       " 'renanvagabundo',\n",
       " 'cpidocirco',\n",
       " 'forabolsonaro',\n",
       " 'forabolsonarogenocida']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "043dc591-ceee-4d60-b5bf-4bb742b944a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_tts = []\n",
    "columns = ['author', 'user_description', 'tweet', 'hashtags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d91f70e-f51b-4975-ba08-e10e827faca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for week in week_list:\n",
    "    print(f'Starting {week}:')\n",
    "    week_df = pd.read_parquet(f'{DATA_PATH+week}/merged_{week}.parquet')\n",
    "    for idx, tweet in week_df.iterrows():\n",
    "        user = eval(tweet['user'])\n",
    "        hashtags = eval(tweet['hashtags'])\n",
    "        #if hashtags and not set(selected_hashtags).isdisjoint(hashtags):\n",
    "        #    split_tts.append([user['username'], user['description'], tweet['content'], hashtags])\n",
    "        if hashtags:\n",
    "            for hashtag in hashtags:\n",
    "                hashtag_lower = hashtag.lower()\n",
    "                if hashtag_lower in selected_hashtags:\n",
    "                    split_tts.append([user['username'], user['description'], tweet['content'], hashtags])\n",
    "                    break\n",
    "    print(f'''\n",
    "    Finished {week}:\n",
    "    Total number of tweets: {len(split_tts)}\n",
    "    \\n\n",
    "    ''')\n",
    "    clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "297b475c-8148-42ef-a676-2d458ea2e425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1554613, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_tt_df = pd.DataFrame(columns=columns, data=split_tts)\n",
    "split_tt_df.drop_duplicates(subset=['author', 'user_description', 'tweet'], keep='last', inplace=True, ignore_index=True)\n",
    "split_tt_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5fd038e-a389-4fa2-991b-6de7920522cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>user_description</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sandroka131</td>\n",
       "      <td>‚ÄúO Brasil que come n√£o conhece o Brasil que te...</td>\n",
       "      <td>@zehdeabreu @verabr1 Mais de 100 pedidos de im...</td>\n",
       "      <td>[CPIdaCovid, GenocidaDesgracado]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thivagando</td>\n",
       "      <td>üè≥Ô∏è‚Äçüåà O antrop√≥logo que logo sou...\\nPalavras-c...</td>\n",
       "      <td>Quase 400 mil mortos no Brasil por Covid-19 e ...</td>\n",
       "      <td>[BolsonaroGenocida, ForaBolsonaro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AndreaPorto2021</td>\n",
       "      <td></td>\n",
       "      <td>@jnascim @planalto Que horror esse @jairbolson...</td>\n",
       "      <td>[ImpeachmentDeBolsonaroUrgente, CPIdaCovid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sandroka131</td>\n",
       "      <td>‚ÄúO Brasil que come n√£o conhece o Brasil que te...</td>\n",
       "      <td>O PT est√° se reunindo com especialistas da sa√∫...</td>\n",
       "      <td>[CPIdaCovid, FINES]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HSarapeck</td>\n",
       "      <td>Rubro-negro, carioca, eleitor de Lula e do PT ...</td>\n",
       "      <td>Interven√ß√£o militar para abrir boates, shoppin...</td>\n",
       "      <td>[CPIdaCovid, ImpeachmentDeBolsonaroUrgente]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author                                   user_description  \\\n",
       "0      Sandroka131  ‚ÄúO Brasil que come n√£o conhece o Brasil que te...   \n",
       "1       thivagando  üè≥Ô∏è‚Äçüåà O antrop√≥logo que logo sou...\\nPalavras-c...   \n",
       "2  AndreaPorto2021                                                      \n",
       "3      Sandroka131  ‚ÄúO Brasil que come n√£o conhece o Brasil que te...   \n",
       "4        HSarapeck  Rubro-negro, carioca, eleitor de Lula e do PT ...   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  @zehdeabreu @verabr1 Mais de 100 pedidos de im...   \n",
       "1  Quase 400 mil mortos no Brasil por Covid-19 e ...   \n",
       "2  @jnascim @planalto Que horror esse @jairbolson...   \n",
       "3  O PT est√° se reunindo com especialistas da sa√∫...   \n",
       "4  Interven√ß√£o militar para abrir boates, shoppin...   \n",
       "\n",
       "                                      hashtags  \n",
       "0             [CPIdaCovid, GenocidaDesgracado]  \n",
       "1           [BolsonaroGenocida, ForaBolsonaro]  \n",
       "2  [ImpeachmentDeBolsonaroUrgente, CPIdaCovid]  \n",
       "3                          [CPIdaCovid, FINES]  \n",
       "4  [CPIdaCovid, ImpeachmentDeBolsonaroUrgente]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_tt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "028c10ec-3252-4a5e-bfb8-44b545c8fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_tt_df.to_parquet(DATA_PATH+'selected_tt_split.parquet', index=False)\n",
    "del(split_tt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecde71c-b4e7-4726-8163-3f13369c3281",
   "metadata": {},
   "source": [
    "## Social Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b11a74-1b68-478f-b139-e12827a1be8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274172"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt_df = pd.read_parquet(DATA_PATH+'selected_tt_split.parquet')\n",
    "usr_list = list(tt_df['author'].value_counts().index)\n",
    "len(usr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "221147f1-2cd7-4caf-b6d3-71cf3c2e1875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the complete network graph\n",
    "tt_network = nx.read_gexf('data/networks/complete_network.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d98be079-b76b-4a39-a63d-d0fcb9389205",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45e51a83-b824-4cd8-a6b9-85829792fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3111f8c6-ed83-41b7-9f13-a7e862e30f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22836/851213609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0musr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0musr\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0musr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musr_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tt_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nodes_len = len(list(tt_network.nodes()))\n",
    "for usr, data in list(tt_network.nodes(data=True)):\n",
    "    if usr not in nodes and usr in usr_list:\n",
    "        nodes.append((usr, data['tt_id'], data['description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d5538-c2cd-469a-a7a4-c5bee30f0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff452b14-e608-4fa7-9e70-24b687943869",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c326f-c45d-4768-ac45-e78bc379556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for usr, tt_id, desc in nodes:\n",
    "    G.add_node(usr, twitter_id=tt_id, description=desc)\n",
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb5ec3-db99-4cad-a0de-178a86e04930",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"data/networks/split_tt_nodes.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80193e1-a70e-4362-a37e-c311f4023da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gexf('data/networks/split_tt_nodes.gexf')\n",
    "len(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c014d0e7-e57f-45a6-94a6-f583877187b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_temp = list(G.nodes())\n",
    "for src, tgt, data in list(tt_network.edges(data=True)):\n",
    "    if src in nodes_temp and tgt in nodes_temp:\n",
    "        edges.append((src, tgt, data['interac_type']))\n",
    "del(nodes_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f67780-8a0b-4271-ba65-27761b0c5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb8755-1e97-4ba5-93a4-c30aff034404",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=edges, columns=['source', 'target', 'type']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68038e-0647-44c0-9793-7df085332064",
   "metadata": {},
   "outputs": [],
   "source": [
    "for src, tgt, int_type in edges:\n",
    "    G.add_edge(src, tgt, interaction_type=int_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3a946-1540-4947-8bce-8169750f035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "Number of nodes: {len(list(G.nodes()))}\n",
    "Number of edges: {len(list(G.edges()))}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094c1dce-fbd1-4ff5-a6a7-731d47c9aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, 'data/networks/split_tt_network.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa99b8f-254e-447c-8a99-5fb4dd77c4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_complete = nx.read_gexf('data/networks/split_tt_network.gexf')\n",
    "list(G_complete.edges(data=True))[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f251494-ecaf-4154-b78d-91c8012f89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_mention = [(src, trg, data) for src, trg, data in G_complete.edges(data=True) if data['interaction_type']=='mention']\n",
    "edges_quoted = [(src, trg, data) for src, trg, data in G_complete.edges(data=True) if data['interaction_type']=='quoted_rt']\n",
    "edges_reply = [(src, trg, data) for src, trg, data in G_complete.edges(data=True) if data['interaction_type']=='reply']\n",
    "\n",
    "G_mention = nx.DiGraph()\n",
    "G_quoted = nx.DiGraph()\n",
    "G_reply = nx.DiGraph()\n",
    "\n",
    "G_mention.add_edges_from(edges_mention)\n",
    "G_quoted.add_edges_from(edges_quoted)\n",
    "G_reply.add_edges_from(edges_reply)\n",
    "\n",
    "G_mention.remove_nodes_from([node for node,degree in dict(G_mention.degree()).items() if degree < 1])\n",
    "G_quoted.remove_nodes_from([node for node,degree in dict(G_quoted.degree()).items() if degree < 1])\n",
    "G_reply.remove_nodes_from([node for node,degree in dict(G_reply.degree()).items() if degree < 1])\n",
    "\n",
    "print(f'''\n",
    "Mention Network: {len(G_mention.nodes())} nodes and {len(edges_mention)} edges\n",
    "Quoted Retweet Network: {len(G_quoted.nodes())} nodes and {len(edges_quoted)} edges\n",
    "Reply Network: edges amount: {len(G_reply.nodes())} nodes and {len(edges_reply)} edges\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ccaf81-a9bb-4b7a-beb8-68f882068b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G_mention, 'data/networks/split_tt_mention_network.gexf')\n",
    "nx.write_gexf(G_quoted, 'data/networks/split_tt_quoted_network.gexf')\n",
    "nx.write_gexf(G_reply, 'data/networks/split_tt_reply_network.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19537816-1047-4b03-86be-0c0b2dd89b32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
