{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc91b0de-02c2-4fad-b000-4f9af65aedeb",
   "metadata": {},
   "source": [
    "# __Tweets Extraction: Brazilian Covid-19 CPI (Parliamentary Commission of Inquiry)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d64bf42-d54f-483f-ad30-9ab586b3253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.variables import hashtag_media, week_list\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import os, itertools, datetime, json\n",
    "from modules.week import Week\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f4d1cc-8bc0-42f1-90b6-ef19597a2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtags(hashtag_series):\n",
    "    hashtag_list = []\n",
    "    for hashtag_group in hashtag_series:\n",
    "        if hashtag_group:\n",
    "            for hashtag in hashtag_group:\n",
    "                if hashtag.lower() not in hashtag_media:\n",
    "                    hashtag_list.append('#'+hashtag.lower())\n",
    "    return hashtag_list\n",
    "\n",
    "def get_unique_hashtags(hashtag_list):\n",
    "    hashtag_series = pd.Series(hashtag_list)\n",
    "    return hashtag_series.unique()\n",
    "\n",
    "def get_hashtag_count(hashtag_list):\n",
    "    return get_unique_hashtags(hashtag_list).size\n",
    "\n",
    "def get_top10(hashtag_list):\n",
    "    hashtag_series = pd.Series(hashtag_list)\n",
    "    return hashtag_series.value_counts().index[:10].tolist()\n",
    "\n",
    "def day_tweet_extract(day):\n",
    "    until = (datetime.datetime.strptime(day, '%Y-%m-%d') + datetime.timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    query = f'cpi AND covid OR pandemia lang:pt since:{day} until:{until}'\n",
    "    print('- Cpi covid|pandemia query extraction:')\n",
    "    start_time = datetime.datetime.now()\n",
    "    tweets_q = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(query).get_items(), None))\n",
    "    runtime = datetime.datetime.now() - start_time\n",
    "    print(f'-- Runtime: {runtime}'\n",
    "         f'\\n-- Tweets amount: {tweets_q.shape[0]}')\n",
    "    hashtag_list_q = get_hashtags(tweets_q['hashtags'])\n",
    "    hashtag_count_q = get_hashtag_count(hashtag_list_q)\n",
    "    unique_hashtags_q = get_unique_hashtags(hashtag_list_q)\n",
    "    hashtag_top10_q = get_top10(hashtag_list_q)\n",
    "    print(f'-- Unique hashtags amount: {hashtag_count_q}'\n",
    "         f'\\n-- Top 10 Hashtags: {hashtag_top10_q}'\n",
    "         '\\n- Hashtag query extraction:')\n",
    "    hashtag_query = ' OR '.join(hashtag_top10_q)\n",
    "    query = f'({hashtag_query}) lang:pt since:{day} until:{until}'\n",
    "    start_time = datetime.datetime.now()\n",
    "    tweets_h = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(query).get_items(), None))\n",
    "    runtime = datetime.datetime.now() - start_time\n",
    "    print(f'-- Runtime: {runtime}'\n",
    "         f'\\n-- Tweets amount: {tweets_h.shape[0]}')\n",
    "    hashtag_list_h = get_hashtags(tweets_h['hashtags'])\n",
    "    hashtag_count_h = get_hashtag_count(hashtag_list_h)\n",
    "    unique_hashtags_h = get_unique_hashtags(hashtag_list_h)\n",
    "    hashtag_top10_h = get_top10(hashtag_list_h)\n",
    "    print(f'-- Unique hashtags amount: {hashtag_count_h}'\n",
    "         f'\\n-- Top 10 Hashtags: {hashtag_top10_h}\\n')\n",
    "    return {\n",
    "        'query_ext': {\n",
    "            'hashtag_count': hashtag_count_q,\n",
    "            'hashtag_top_10': hashtag_top10_q,\n",
    "            'unique_hashtags': unique_hashtags_q,\n",
    "            'tweets': tweets_q\n",
    "        },\n",
    "        'hashtag_ext': {\n",
    "            'hashtag_count': hashtag_count_h,\n",
    "            'hashtag_top_10': hashtag_top10_h,\n",
    "            'unique_hashtags': unique_hashtags_h,\n",
    "            'tweets': tweets_h\n",
    "        }\n",
    "    }\n",
    "\n",
    "def week_tweet_extract(week):\n",
    "    week_dir = f'data/tweets/week_{week.number}'\n",
    "    if not os.path.exists(week_dir):\n",
    "        os.mkdir(week_dir)\n",
    "    print(f'====== EXTRACTING FROM WEEK {week.number}: SINCE {week.start} UNTIL {week.end} ======'\n",
    "         f'\\n\\nData is being stored in the following directory: {week_dir}\\n')\n",
    "    week_info = week.info\n",
    "    week_hashtags = {\n",
    "        'query_ext': [],\n",
    "        'hashtag_ext': []\n",
    "    }\n",
    "    week_tweets_amount = {\n",
    "        'query_ext': 0,\n",
    "        'hashtag_ext': 0\n",
    "    }\n",
    "    for idx, day in enumerate(week.days):\n",
    "        _day = f'day_{idx+1}'\n",
    "        deponents = week_info['days_info'][_day]['deponents']\n",
    "        print(f'Extracting tweets from Day: {idx+1}: {day}'\n",
    "             f'\\n- Deponents of the day: {deponents}')\n",
    "        day_ext = day_tweet_extract(day)\n",
    "        week_info['days_info'][_day]['tweets_amount'] = {\n",
    "            'query_ext': day_ext['query_ext']['tweets'].shape[0],\n",
    "            'hashtag_ext': day_ext['hashtag_ext']['tweets'].shape[0]\n",
    "        }\n",
    "        week_info['days_info'][_day]['hashtags_amount'] = {\n",
    "            'query_ext': day_ext['query_ext']['hashtag_count'],\n",
    "            'hashtag_ext': day_ext['hashtag_ext']['hashtag_count']\n",
    "        }\n",
    "        week_info['days_info'][_day]['top_10_hashtags'] = {\n",
    "            'query_ext': day_ext['query_ext']['hashtag_top_10'],\n",
    "            'hashtag_ext': day_ext['hashtag_ext']['hashtag_top_10']\n",
    "        }\n",
    "        week_tweets_amount = {\n",
    "            'query_ext': week_tweets_amount['query_ext'] + day_ext['query_ext']['tweets'].shape[0],\n",
    "            'hashtag_ext': week_tweets_amount['hashtag_ext'] + day_ext['hashtag_ext']['tweets'].shape[0]\n",
    "        }\n",
    "        for hashtag in day_ext['query_ext']['unique_hashtags']:\n",
    "            week_hashtags['query_ext'].append(hashtag)\n",
    "        for hashtag in day_ext['hashtag_ext']['unique_hashtags']:\n",
    "            week_hashtags['hashtag_ext'].append(hashtag)\n",
    "        day_ext['query_ext']['tweets'].astype(str).to_parquet(f'{week_dir}/{_day}_{day}_query_ext.parquet')\n",
    "        day_ext['hashtag_ext']['tweets'].astype(str).to_parquet(f'{week_dir}/{_day}_{day}_hashtags_ext.parquet')\n",
    "    week_info['tweets_amount'] = week_tweets_amount\n",
    "    week_info['hashtags_amount'] = {\n",
    "        'query_ext': get_hashtag_count(week_hashtags['query_ext']),\n",
    "        'hashtag_ext': get_hashtag_count(week_hashtags['hashtag_ext'])\n",
    "    }\n",
    "    week_info['top_10_hashtags'] = {\n",
    "        'query_ext': get_top10(week_hashtags['query_ext']),\n",
    "        'hashtag_ext': get_top10(week_hashtags['hashtag_ext'])\n",
    "    }\n",
    "    print('Generating week info json file...\\n')\n",
    "    with open(week_dir + f'/week_{week.number}_info.json', 'w') as json_file:\n",
    "        json.dump(week_info, json_file, indent=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680245cf-af87-4562-90fa-59259887eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deponents = {\n",
    "#     #'day_3': [],\n",
    "#     #'day_4': [],\n",
    "#     #'day_5': []\n",
    "# }\n",
    "\n",
    "# week = Week(week_number=1,\n",
    "#            week_start='2021-04-25',\n",
    "#            deponents=deponents)\n",
    "\n",
    "# week_tweet_extract(week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0e8409-d34a-4863-9feb-743d833bef54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== EXTRACTING FROM WEEK 21: SINCE 2021-10-03 UNTIL 2021-10-09 ======\n",
      "\n",
      "Data is being stored in the following directory: data/tweets/week_21\n",
      "\n",
      "Extracting tweets from Day: 1: 2021-10-03\n",
      "- Deponents of the day: []\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:00:25.982819\n",
      "-- Tweets amount: 529\n",
      "-- Unique hashtags amount: 47\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#brasil', '#forabolsonaro', '#cpidocirco', '#cpi', '#bolsonaroreeleito', '#cpidapandemia', '#calabocajamorreu', '#2outforabolsonaro', '#forabolsonarogenocida']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:06:58.020577\n",
      "-- Tweets amount: 9478\n",
      "-- Unique hashtags amount: 2155\n",
      "-- Top 10 Hashtags: ['#bolsonaroreeleito', '#forabolsonaro', '#2outforabolsonaro', '#forabolsonarogenocida', '#brasil', '#lulalivrebrasillivre', '#tácaroculpadobolsonaro', '#bolsonaroate2026', '#cpidocirco', '#fiascogigante']\n",
      "\n",
      "Extracting tweets from Day: 2: 2021-10-04\n",
      "- Deponents of the day: []\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:00:37.945721\n",
      "-- Tweets amount: 860\n",
      "-- Unique hashtags amount: 74\n",
      "-- Top 10 Hashtags: ['#cpi', '#cpidacovid', '#cpidapandemia', '#pandorapapers', '#2outforabolsonaro', '#lulalivrebrasillivre', '#tácaroculpadobolsonaro', '#amazonas', '#cpidocirco', '#preventsenior']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:02:38.670566\n",
      "-- Tweets amount: 3441\n",
      "-- Unique hashtags amount: 876\n",
      "-- Top 10 Hashtags: ['#pandorapapers', '#2outforabolsonaro', '#lulalivrebrasillivre', '#tácaroculpadobolsonaro', '#cpidocirco', '#cpidacovid', '#amazonas', '#manaus', '#pandoraleaks', '#forabolsonaro']\n",
      "\n",
      "Extracting tweets from Day: 3: 2021-10-05\n",
      "- Deponents of the day: ['Raimundo Nonato Basil']\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:01:07.599244\n",
      "-- Tweets amount: 1445\n",
      "-- Unique hashtags amount: 148\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#cpidapandemia', '#cpidocirco', '#cpi', '#2outforabolsonaro', '#lulalivrebrasillivre', '#tácaroculpadobolsonaro', '#vtclog', '#pandemia', '#cirogames']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:04:16.475191\n",
      "-- Tweets amount: 6736\n",
      "-- Unique hashtags amount: 684\n",
      "-- Top 10 Hashtags: ['#cirogames', '#cpidacovid', '#2outforabolsonaro', '#lulalivrebrasillivre', '#tácaroculpadobolsonaro', '#cpidapandemia', '#cpidocirco', '#cpidacovid19', '#pandemia', '#cpi']\n",
      "\n",
      "Extracting tweets from Day: 4: 2021-10-06\n",
      "- Deponents of the day: []\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:01:19.689753\n",
      "-- Tweets amount: 1807\n",
      "-- Unique hashtags amount: 134\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#cpidapandemia', '#tácaroculpadobolsonaro', '#2outforabolsonaro', '#lulalivrebrasillivre', '#cpidocirco', '#cpi', '#cpidacovid19', '#covid19', '#ansassumaseupapel']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:03:11.735329\n",
      "-- Tweets amount: 4234\n",
      "-- Unique hashtags amount: 924\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#cpidocirco', '#2outforabolsonaro', '#cpidapandemia', '#lulalivrebrasillivre', '#tácaroculpadobolsonaro', '#covid19', '#cpidacovid19', '#coronavirus', '#cpi']\n",
      "\n",
      "Extracting tweets from Day: 5: 2021-10-07\n",
      "- Deponents of the day: ['Paulo Rebeiro Filho']\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:01:41.310476\n",
      "-- Tweets amount: 2357\n",
      "-- Unique hashtags amount: 201\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#cpidapandemia', '#cpi', '#cpidacovid19', '#médicossalvamvidasdeixemosmédicosempaz', '#lulalivrebrasillivre', '#forabolsonaro', '#deixemosmédicosempaz', '#2outforabolsonaro', '#tácaroculpadobolsonaro']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:05:40.742791\n",
      "-- Tweets amount: 8585\n",
      "-- Unique hashtags amount: 1049\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#forabolsonaro', '#cpidapandemia', '#cpidacovid19', '#2outforabolsonaro', '#lulalivrebrasillivre', '#tácaroculpadobolsonaro', '#forabolsonarogenocida', '#bolsonarogenocida', '#preventsenior']\n",
      "\n",
      "Extracting tweets from Day: 6: 2021-10-08\n",
      "- Deponents of the day: ['Walter Correa de Souza Netto', 'Tadeu Frederico Andrade']\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:00:49.737359\n",
      "-- Tweets amount: 1015\n",
      "-- Unique hashtags amount: 76\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#cpi', '#covid19', '#forabolsonaro', '#2outforabolsonaro', '#déalúcia', '#cpidocirco', '#lulalivrebrasillivre', '#tácaroculpadobolsonaro', '#preventsenior']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:04:30.478641\n",
      "-- Tweets amount: 5658\n",
      "-- Unique hashtags amount: 1627\n",
      "-- Top 10 Hashtags: ['#forabolsonaro', '#lulalivrebrasillivre', '#2outforabolsonaro', '#tácaroculpadobolsonaro', '#covid19', '#cpidocirco', '#cpidacovid', '#forabolsonarogenocida', '#vivaosus', '#foraguedes']\n",
      "\n",
      "Extracting tweets from Day: 7: 2021-10-09\n",
      "- Deponents of the day: []\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:00:33.264399\n",
      "-- Tweets amount: 645\n",
      "-- Unique hashtags amount: 50\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#cpi', '#covid19', '#cfm', '#cpidocirco', '#paulogustavo', '#bolsonarogenocida', '#bolsonaro', '#mauropinheironacpija', '#lulapresidentehaddadgovsp']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:02:42.596099\n",
      "-- Tweets amount: 3208\n",
      "-- Unique hashtags amount: 789\n",
      "-- Top 10 Hashtags: ['#lulapresidentehaddadgovsp', '#bolsonarogenocida', '#covid19', '#cpidocirco', '#bolsonaro', '#cpidacovid', '#forabolsonaro', '#coronavirus', '#lulapresidente2022', '#forabolsonarogenocida']\n",
      "\n",
      "Generating week info json file...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for week in week_list:\n",
    "    _week = Week(week_number=week['week_number'],\n",
    "                week_start=week['week_start'],\n",
    "                deponents=week['deponents'])\n",
    "    week_tweet_extract(_week)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-cpi",
   "language": "python",
   "name": "twitter-cpi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
