{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc91b0de-02c2-4fad-b000-4f9af65aedeb",
   "metadata": {},
   "source": [
    "# __Tweets Extraction: Brazilian Covid-19 CPI (Parliamentary Commission of Inquiry)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d64bf42-d54f-483f-ad30-9ab586b3253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.variables import hashtag_media, week_list\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import os, itertools, datetime, json\n",
    "from modules.week import Week\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17f4d1cc-8bc0-42f1-90b6-ef19597a2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMNS = ['id', 'url', 'date', 'content', 'rendered_content', 'user_id', 'username', 'user_display_name', 'user_description',\n",
    "#           'user_description_urls', 'user_verified', 'user_created', 'user_followers_count', 'user_friends_counts', 'user_status_count', 'user_favourites_count',\n",
    "#           'user_listed_count', 'user_media_count', 'user_location', 'user_protected', 'user_url', 'user_profile_pic', 'user_profile_banner',\n",
    "#           'reply_count', 'retweet_count', 'like_count', 'quote_count', 'conversation_id', 'media', 'retweeted_tweet', 'quoted_tweet',\n",
    "#           'in_reply_to_tweet_id', 'in_reply_to_user', 'mentioned_users', 'coordinates', 'place', 'hashtags', 'cashtags']\n",
    "\n",
    "def get_hashtags(hashtag_series):\n",
    "    hashtag_list = []\n",
    "    for hashtag_group in hashtag_series:\n",
    "        if hashtag_group:\n",
    "            for hashtag in hashtag_group:\n",
    "                if hashtag.lower() not in hashtag_media:\n",
    "                    hashtag_list.append('#'+hashtag.lower())\n",
    "    return hashtag_list\n",
    "\n",
    "def get_unique_hashtags(hashtag_list):\n",
    "    hashtag_series = pd.Series(hashtag_list)\n",
    "    return hashtag_series.unique()\n",
    "\n",
    "def get_hashtag_count(hashtag_list):\n",
    "    return get_unique_hashtags(hashtag_list).size\n",
    "\n",
    "def get_top10(hashtag_list):\n",
    "    hashtag_series = pd.Series(hashtag_list)\n",
    "    return hashtag_series.value_counts().index[:10].tolist()\n",
    "\n",
    "def day_tweet_extract(day):\n",
    "    until = (datetime.datetime.strptime(day, '%Y-%m-%d') + datetime.timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    query = f'cpi AND covid OR pandemia lang:pt since:{day} until:{until}'\n",
    "    print('- Cpi covid|pandemia query extraction:')\n",
    "#    tweets_list = []\n",
    "    start_time = datetime.datetime.now()\n",
    "#     for idx, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "#         tweets_list.append([tweet.id, tweet.url, tweet.date, tweet.content, tweet.renderedContent, tweet.user.id, tweet.user.username, tweet.user.displayname, tweet.user.description,\n",
    "#           tweet.user.descriptionUrls, tweet.user.verified, tweet.user.created, tweet.user.followersCount, tweet.user.friendsCount, tweet.user.statusesCount, tweet.user.favouritesCount,\n",
    "#           tweet.user.listedCount, tweet.user.mediaCount, tweet.user.location, tweet.user.protected, tweet.user.linkUrl, tweet.user.profileImageUrl, tweet.user.profileBannerUrl,\n",
    "#           tweet.replyCount, tweet.retweetCount, tweet.likeCount, tweet.quoteCount, tweet.conversationId, tweet.media, tweet.retweetedTweet, tweet.quotedTweet,\n",
    "#           tweet.inReplyToTweetId, tweet.inReplyToUser, tweet.mentionedUsers, tweet.coordinates, tweet.place, tweet.hashtags, tweet.cashtags])\n",
    "#     tweets_q = pd.DataFrame(tweets_list, columns=COLUMNS)\n",
    "    tweets_q = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(query).get_items(), None))\n",
    "    runtime = datetime.datetime.now() - start_time\n",
    "    print(f'-- Runtime: {runtime}'\n",
    "         f'\\n-- Tweets amount: {tweets_q.shape[0]}')\n",
    "    hashtag_list_q = get_hashtags(tweets_q['hashtags'])\n",
    "    hashtag_count_q = get_hashtag_count(hashtag_list_q)\n",
    "    unique_hashtags_q = get_unique_hashtags(hashtag_list_q)\n",
    "    hashtag_top10_q = get_top10(hashtag_list_q)\n",
    "    print(f'-- Unique hashtags amount: {hashtag_count_q}'\n",
    "         f'\\n-- Top 10 Hashtags: {hashtag_top10_q}'\n",
    "         '\\n- Hashtag query extraction:')\n",
    "    hashtag_query = ' OR '.join(hashtag_top10_q)\n",
    "    query = f'({hashtag_query}) lang:pt since:{day} until:{until}'\n",
    "    start_time = datetime.datetime.now()\n",
    "#    tweets_list = []\n",
    "#     for idx, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "#         tweets_list.append([tweet.id, tweet.url, tweet.date, tweet.content, tweet.renderedContent, tweet.user.id, tweet.user.username, tweet.user.displayname, tweet.user.description,\n",
    "#           tweet.user.descriptionUrls, tweet.user.verified, tweet.user.created, tweet.user.followersCount, tweet.user.friendsCount, tweet.user.statusesCount, tweet.user.favouritesCount,\n",
    "#           tweet.user.listedCount, tweet.user.mediaCount, tweet.user.location, tweet.user.protected, tweet.user.linkUrl, tweet.user.profileImageUrl, tweet.user.profileBannerUrl,\n",
    "#           tweet.replyCount, tweet.retweetCount, tweet.likeCount, tweet.quoteCount, tweet.conversationId, tweet.media, tweet.retweetedTweet, tweet.quotedTweet,\n",
    "#           tweet.inReplyToTweetId, tweet.inReplyToUser, tweet.mentionedUsers, tweet.coordinates, tweet.place, tweet.hashtags, tweet.cashtags])\n",
    "#     tweets_h = pd.DataFrame(tweets_list, columns=COLUMNS)\n",
    "    tweets_h = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(query).get_items(), None))\n",
    "    runtime = datetime.datetime.now() - start_time\n",
    "    print(f'-- Runtime: {runtime}'\n",
    "         f'\\n-- Tweets amount: {tweets_h.shape[0]}')\n",
    "    hashtag_list_h = get_hashtags(tweets_h['hashtags'])\n",
    "    hashtag_count_h = get_hashtag_count(hashtag_list_h)\n",
    "    unique_hashtags_h = get_unique_hashtags(hashtag_list_h)\n",
    "    hashtag_top10_h = get_top10(hashtag_list_h)\n",
    "    print(f'-- Unique hashtags amount: {hashtag_count_h}'\n",
    "         f'\\n-- Top 10 Hashtags: {hashtag_top10_h}\\n')\n",
    "    return {\n",
    "        'query_ext': {\n",
    "            'hashtag_count': hashtag_count_q,\n",
    "            'hashtag_top_10': hashtag_top10_q,\n",
    "            'unique_hashtags': unique_hashtags_q,\n",
    "            'tweets': tweets_q\n",
    "        },\n",
    "        'hashtag_ext': {\n",
    "            'hashtag_count': hashtag_count_h,\n",
    "            'hashtag_top_10': hashtag_top10_h,\n",
    "            'unique_hashtags': unique_hashtags_h,\n",
    "            'tweets': tweets_h\n",
    "        }\n",
    "    }\n",
    "\n",
    "def week_tweet_extract(week):\n",
    "    week_dir = f'data/tweets/week_{week.number}'\n",
    "    if not os.path.exists(week_dir):\n",
    "        os.mkdir(week_dir)\n",
    "    print(f'====== EXTRACTING FROM WEEK {week.number}: SINCE {week.start} UNTIL {week.end} ======'\n",
    "         f'\\n\\nData is being stored in the following directory: {week_dir}\\n')\n",
    "    week_info = week.info\n",
    "    week_hashtags = {\n",
    "        'query_ext': [],\n",
    "        'hashtag_ext': []\n",
    "    }\n",
    "    week_tweets_amount = {\n",
    "        'query_ext': 0,\n",
    "        'hashtag_ext': 0\n",
    "    }\n",
    "    for idx, day in enumerate(week.days):\n",
    "        _day = f'day_{idx+1}'\n",
    "        deponents = week_info['days_info'][_day]['deponents']\n",
    "        print(f'Extracting tweets from Day: {idx+1}: {day}'\n",
    "             f'\\n- Deponents of the day: {deponents}')\n",
    "        day_ext = day_tweet_extract(day)\n",
    "        week_info['days_info'][_day]['tweets_amount'] = {\n",
    "            'query_ext': day_ext['query_ext']['tweets'].shape[0],\n",
    "            'hashtag_ext': day_ext['hashtag_ext']['tweets'].shape[0]\n",
    "        }\n",
    "        week_info['days_info'][_day]['hashtags_amount'] = {\n",
    "            'query_ext': day_ext['query_ext']['hashtag_count'],\n",
    "            'hashtag_ext': day_ext['hashtag_ext']['hashtag_count']\n",
    "        }\n",
    "        week_info['days_info'][_day]['top_10_hashtags'] = {\n",
    "            'query_ext': day_ext['query_ext']['hashtag_top_10'],\n",
    "            'hashtag_ext': day_ext['hashtag_ext']['hashtag_top_10']\n",
    "        }\n",
    "        week_tweets_amount = {\n",
    "            'query_ext': week_tweets_amount['query_ext'] + day_ext['query_ext']['tweets'].shape[0],\n",
    "            'hashtag_ext': week_tweets_amount['hashtag_ext'] + day_ext['hashtag_ext']['tweets'].shape[0]\n",
    "        }\n",
    "        for hashtag in day_ext['query_ext']['unique_hashtags']:\n",
    "            week_hashtags['query_ext'].append(hashtag)\n",
    "        for hashtag in day_ext['hashtag_ext']['unique_hashtags']:\n",
    "            week_hashtags['hashtag_ext'].append(hashtag)\n",
    "#         day_ext['query_ext']['tweets']['date'] = day_ext['query_ext']['tweets']['date'].map(lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "#         day_ext['hashtag_ext']['tweets']['date'] = day_ext['query_ext']['tweets']['date'].map(lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "        day_ext['query_ext']['tweets'].astype(str).to_parquet(f'{week_dir}/{_day}_{day}_query_ext.parquet')\n",
    "        day_ext['hashtag_ext']['tweets'].astype(str).to_parquet(f'{week_dir}/{_day}_{day}_hashtags_ext.parquet')\n",
    "    week_info['tweets_amount'] = week_tweets_amount\n",
    "    week_info['hashtags_amount'] = {\n",
    "        'query_ext': get_hashtag_count(week_hashtags['query_ext']),\n",
    "        'hashtag_ext': get_hashtag_count(week_hashtags['hashtag_ext'])\n",
    "    }\n",
    "    week_info['top_10_hashtags'] = {\n",
    "        'query_ext': get_top10(week_hashtags['query_ext']),\n",
    "        'hashtag_ext': get_top10(week_hashtags['hashtag_ext'])\n",
    "    }\n",
    "    print('Generating week info json file...\\n')\n",
    "    with open(week_dir + f'/week_{week.number}_info.json', 'w') as json_file:\n",
    "        json.dump(week_info, json_file, indent=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680245cf-af87-4562-90fa-59259887eff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deponents = {\n",
    "#     #'day_3': [],\n",
    "#     #'day_4': [],\n",
    "#     #'day_5': []\n",
    "# }\n",
    "\n",
    "# week = Week(week_number=1,\n",
    "#            week_start='2021-04-25',\n",
    "#            deponents=deponents)\n",
    "\n",
    "# week_tweet_extract(week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0e8409-d34a-4863-9feb-743d833bef54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== EXTRACTING FROM WEEK 18: SINCE 2021-09-12 UNTIL 2021-09-18 ======\n",
      "\n",
      "Data is being stored in the following directory: data/tweets/week_18\n",
      "\n",
      "Extracting tweets from Day: 1: 2021-09-12\n",
      "- Deponents of the day: []\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:00:20.288267\n",
      "-- Tweets amount: 206\n",
      "-- Unique hashtags amount: 12\n",
      "-- Top 10 Hashtags: ['#derretembl', '#forabolsonaro', '#bolsonaroate2026', '#bolsonaroorgulhodobrasil', '#cnndomingo', '#8milhõesqueeram', '#apandemiaemportel', '#cpitenta', '#paracombater', '#bolsonarosembangu8']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:25:50.142573\n",
      "-- Tweets amount: 24171\n",
      "-- Unique hashtags amount: 1770\n",
      "-- Top 10 Hashtags: ['#derretembl', '#forabolsonaro', '#bolsonaroate2026', '#bolsonaroorgulhodobrasil', '#derretenovaesquerda', '#cironapaulista', '#bolsonarotemrazao', '#domingoadeusbolsonaro', '#forabolsonarogenocida', '#euconfionopresidente']\n",
      "\n",
      "Extracting tweets from Day: 2: 2021-09-13\n",
      "- Deponents of the day: []\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:00:49.276572\n",
      "-- Tweets amount: 737\n",
      "-- Unique hashtags amount: 72\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#stopbolsonaromundial', '#lulalivrebrasillivre', '#7sforabolsonaro', '#covid', '#cpidapandemia', '#cpi', '#pandemia', '#forabolsonaro', '#impeachmentbolsonarourgente']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:04:37.158201\n",
      "-- Tweets amount: 4316\n",
      "-- Unique hashtags amount: 1206\n",
      "-- Top 10 Hashtags: ['#forabolsonaro', '#lulalivrebrasillivre', '#7sforabolsonaro', '#stopbolsonaromundial', '#impeachmentbolsonarourgente', '#covid', '#cpidacovid', '#vivaosus', '#forabolsonarogenocida', '#pandemia']\n",
      "\n",
      "Extracting tweets from Day: 3: 2021-09-14\n",
      "- Deponents of the day: ['Marcos Tolentino']\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:01:26.695996\n",
      "-- Tweets amount: 1270\n",
      "-- Unique hashtags amount: 94\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#cpidapandemia', '#f', '#cpidacovid19', '#7sforabolsonaro', '#stopbolsonaromundial', '#lulalivrebrasillivre', '#marcostolentino', '#cpi', '#cpidocirco']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:03:36.328980\n",
      "-- Tweets amount: 4084\n",
      "-- Unique hashtags amount: 372\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#cpidapandemia', '#lulalivrebrasillivre', '#7sforabolsonaro', '#stopbolsonaromundial', '#cpidacovid19', '#cpidocirco', '#cpi', '#forabolsonaro', '#cpidogenocidio']\n",
      "\n",
      "Extracting tweets from Day: 4: 2021-09-15\n",
      "- Deponents of the day: ['Marconny Faria']\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:02:34.064638\n",
      "-- Tweets amount: 2257\n",
      "-- Unique hashtags amount: 165\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#cpidapandemia', '#cpi', '#forabolsonaro', '#cpidacovid19', '#bolsonaro', '#bolsonaroladrao', '#stopbolsonaromundial', '#lulalivrebrasillivre', '#7sforabolsonaro']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:11:57.898625\n",
      "-- Tweets amount: 12712\n",
      "-- Unique hashtags amount: 1351\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#forabolsonaro', '#bolsonaroladrão', '#bolsonaroladrao', '#cpidapandemia', '#cpidacovid19', '#lulalivrebrasillivre', '#7sforabolsonaro', '#stopbolsonaromundial', '#bolsonaro']\n",
      "\n",
      "Extracting tweets from Day: 5: 2021-09-16\n",
      "- Deponents of the day: []\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:01:51.892114\n",
      "-- Tweets amount: 1886\n",
      "-- Unique hashtags amount: 142\n",
      "-- Top 10 Hashtags: ['#cpidacovid', '#cpi', '#cpidapandemia', '#preventsenior', '#7sforabolsonaro', '#stopbolsonaromundial', '#lulalivrebrasillivre', '#covid', '#cpidafakeada', '#forabolsonaro']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:04:34.345496\n",
      "-- Tweets amount: 4464\n",
      "-- Unique hashtags amount: 1129\n",
      "-- Top 10 Hashtags: ['#forabolsonaro', '#cpidacovid', '#7sforabolsonaro', '#lulalivrebrasillivre', '#stopbolsonaromundial', '#preventsenior', '#cpidapandemia', '#vivaosus', '#covid', '#forabolsonarogenocida']\n",
      "\n",
      "Extracting tweets from Day: 6: 2021-09-17\n",
      "- Deponents of the day: []\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:01:22.232293\n",
      "-- Tweets amount: 1184\n",
      "-- Unique hashtags amount: 114\n",
      "-- Top 10 Hashtags: ['#cpi', '#cpidapandemia', '#lulalivrebrasillivre', '#7sforabolsonaro', '#stopbolsonaromundial', '#cpidacovid', '#chamabraganetto', '#bolsonaro', '#forabolsonaro', '#covid']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:04:28.461297\n",
      "-- Tweets amount: 4188\n",
      "-- Unique hashtags amount: 1329\n",
      "-- Top 10 Hashtags: ['#forabolsonaro', '#lulalivrebrasillivre', '#7sforabolsonaro', '#stopbolsonaromundial', '#cpidacovid', '#bolsonaro', '#forabolsonarogenocida', '#covid', '#vivaosus', '#cpidapandemia']\n",
      "\n",
      "Extracting tweets from Day: 7: 2021-09-18\n",
      "- Deponents of the day: []\n",
      "- Cpi covid|pandemia query extraction:\n",
      "-- Runtime: 0:00:32.826325\n",
      "-- Tweets amount: 432\n",
      "-- Unique hashtags amount: 29\n",
      "-- Top 10 Hashtags: ['#cpi', '#stopbolsonaromundial', '#lulalivrebrasillivre', '#7sforabolsonaro', '#forabolsonaro', '#forabolsonarogenocida', '#cpidacovid', '#opinião', '#candeiasmix', '#euconfionopresidente']\n",
      "- Hashtag query extraction:\n",
      "-- Runtime: 0:03:35.292347\n",
      "-- Tweets amount: 3481\n",
      "-- Unique hashtags amount: 848\n",
      "-- Top 10 Hashtags: ['#forabolsonaro', '#forabolsonarogenocida', '#euconfionopresidente', '#lulalivrebrasillivre', '#stopbolsonaromundial', '#7sforabolsonaro', '#vivaosus', '#cpidacovid', '#bolsonaroacabou', '#impeachmentbolsonaro']\n",
      "\n",
      "Generating week info json file...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for week in week_list:\n",
    "    _week = Week(week_number=week['week_number'],\n",
    "                week_start=week['week_start'],\n",
    "                deponents=week['deponents'])\n",
    "    week_tweet_extract(_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69202b00-f970-4bfe-a782-cba600fb2f1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-twitter-cpi] *",
   "language": "python",
   "name": "conda-env-.conda-twitter-cpi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
